{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "8_Tree-Based_Models.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0731325603/Capstone/blob/master/8_Tree_Based_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjHtSmjFxTJT",
        "colab_type": "text"
      },
      "source": [
        "# Tree-based Models for Classification\n",
        "Â© Explore Data Science Academy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrQRTmnCxTJZ",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "By the end of this train, you should be able to:\n",
        "\n",
        "- Build Decision Tree and Random Forest classification models using `sklearn`;\n",
        "- Understand how tree-based models work in the classification setting.\n",
        "\n",
        "## Outline\n",
        "\n",
        "In this train we will:\n",
        "\n",
        "- Load and Preprocess the Iris dataset;\n",
        "- Train a Decision Tree Classifier;\n",
        "- Train a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHUQBowHxTJc",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "You would have covered __decision trees__ and __random forests__ during the regression sprint. In this train we will discuss these tree-based models for their use in classification. If you do need a refresher on these tree-based models, be sure to check out the previous trains. Here are the links to the relevant videos:\n",
        "\n",
        "- [Decision Trees for Regression](https://youtu.be/6UwBOkKOUGk);\n",
        "- [Random Forest for Regression](https://youtu.be/UbUDwk0BjuI);\n",
        "- [Ensemble Methods for Regression](https://youtu.be/3uHrFDDs_RE), which typically make use of decision trees as the base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-SXSP33xTJf",
        "colab_type": "text"
      },
      "source": [
        "## Decision Trees\n",
        "\n",
        "In a previous tutorial we covered how to build a decision tree regression model. In this tutorial we will look at how to build a decision tree classification model. Let's refresh our memories about decision trees:\n",
        "\n",
        "### What is a Decision Tree?\n",
        "\n",
        "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences. It is one way to display an algorithm that only contains conditional control statements.\n",
        "\n",
        "Decision trees are extremely intuitive ways to classify objects or predict continuous values: you simply ask a series of questions designed to zero-in on the classification/prediction. For example, if you wanted to build a decision tree to classify an animal you come across while on a hike, you might construct the one shown here:\n",
        "\n",
        "<img src=\"https://cocalc.com/share/e9d2f604-5c15-48c1-8c69-4d560cf9a933/PythonDataScienceHandbook/notebooks/figures/05.08-decision-tree.png\">\n",
        "\n",
        "The binary splitting makes this extremely efficient: in a well-constructed tree, each question will cut the number of options by approximately half, very quickly narrowing the options even among a large number of classes.\n",
        "The trick, of course, comes in deciding which questions to ask at each step.\n",
        "In machine learning implementations of decision trees, the questions generally take the form of axis-aligned splits in the data, that is, each node in the tree splits the data into two groups using a cutoff value within one of the features.\n",
        "\n",
        "The predictions made by the tree are the _modes_ of the class labels in each specific group of observations (i.e.: the training data). This is different to regression, where the predictions were the _means_ of the response values in each group.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-classification-tree-mode.png\" alt=\"sketch-classification-tree-mode\" style=\"width: 400px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ1PDe7gxTJi",
        "colab_type": "text"
      },
      "source": [
        "### Building a Decision Tree Classification Model\n",
        "\n",
        "Let's work through an example of how to create a decision tree classifier using `sklearn`. \n",
        "\n",
        "#### Imports\n",
        "Here we import all the packages we will need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8H9Mr5ExTJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im5PQ2okxTJt",
        "colab_type": "text"
      },
      "source": [
        "#### Data\n",
        "In this train the dataset we will be using is the Iris dataset which you used in Coding Challenge 1. The Iris dataset is a multivariate dataset where each class refers to a type of Iris plant. This dataset is free and is publicly available at the UCI Machine Learning Repository.\n",
        "\n",
        "This dataset contains a set of 150 records with five attributes - Sepal Length, Sepal Width, Petal Length, Petal Width, and Species. Species is the type of Iris plant we will be classifying.\n",
        "\n",
        "Lets import the data to see what we are dealing with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLiXM9ddxTJu",
        "colab_type": "code",
        "colab": {},
        "outputId": "12222eac-a6ad-4765-a0de-835b056fa1d7"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint/iris.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg1KnLBAxTJ1",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-Processing\n",
        "We will start by pre-processing the data so that we can run it through the algorithm. This involves:\n",
        "\n",
        "- Splitting the data into features and labels;\n",
        "- Standardise the data using `sklearn`'s `StandardScaler`;\n",
        "- Splitting the data into training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijHaLGeAxTJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['species']\n",
        "X = df.drop('species', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz9lPPDbxTJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standarise the data\n",
        "standard_scaler = StandardScaler()\n",
        "X_transformed = standard_scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxrh89JJxTKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.30, random_state=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFFXhUPPxTKE",
        "colab_type": "text"
      },
      "source": [
        "#### Training\n",
        "We will now fit a Decision Tree Classification model to our data by using `sklearn`'s `DecisionTreeClassifier` with default parameters and a random state of 42 (because 42 is the answer to life, the universe, and everything)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZekviQG2xTKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree = DecisionTreeClassifier(random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYRVFL8xTKK",
        "colab_type": "code",
        "colab": {},
        "outputId": "aa8fa143-587d-4a96-d1f2-04bd2caba7fa"
      },
      "source": [
        "tree.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Seb5CKxTKP",
        "colab_type": "text"
      },
      "source": [
        "#### Testing\n",
        "\n",
        "Now let's predict the labels for our test set and examine the performance of our model using a confusion matix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGD9fI4DxTKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = tree.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1jKS82DxTKW",
        "colab_type": "text"
      },
      "source": [
        "I'm curious to see how many of each class we have in this test set. Let's print that off before we print out the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYrQlgn6xTKX",
        "colab_type": "code",
        "colab": {},
        "outputId": "af33a4ed-8c61-4e49-e298-3459dd68e03c"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Iris-versicolor    17\n",
              "Iris-setosa        14\n",
              "Iris-virginica     14\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ZY7-AqxTKd",
        "colab_type": "code",
        "colab": {},
        "outputId": "dda05a61-0333-4d08-f824-66673a59a9a3"
      },
      "source": [
        "labels = ['Iris-setosa', 'Iris-versicolor','Iris-virginica']\n",
        "\n",
        "pd.DataFrame(data=confusion_matrix(y_test, y_pred), index=labels, columns=labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Iris-setosa</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iris-virginica</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "Iris-setosa               14                0               0\n",
              "Iris-versicolor            0               16               1\n",
              "Iris-virginica             0                1              13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8zxL99rxTKi",
        "colab_type": "text"
      },
      "source": [
        "Our model does extremely well! Let's also take a look at the classification report for our predicted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI7RFIOYxTKj",
        "colab_type": "code",
        "colab": {},
        "outputId": "5c2bddef-0343-45a4-bd3b-9e94d3043c88"
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=['Iris-setosa', 'Iris-versicolor','Iris-virginica']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        14\n",
            "Iris-versicolor       0.94      0.94      0.94        17\n",
            " Iris-virginica       0.93      0.93      0.93        14\n",
            "\n",
            "       accuracy                           0.96        45\n",
            "      macro avg       0.96      0.96      0.96        45\n",
            "   weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj6lBSTWxTKo",
        "colab_type": "text"
      },
      "source": [
        "Even though our model does really well, you can use this classification report to gain some insight into how to improve it. You can see here that `Iris-virginica` has the lowest f1-score. This could be due to this class having a smaller number of samples. If you were the researcher involved in creating this dataset, you might use this insight as reason to collect more data on `Iris-virginica.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amcFbGSSxTKp",
        "colab_type": "text"
      },
      "source": [
        "### Tuning parameters to improve the model\n",
        "\n",
        "For the decision tree algorithm we can tune parameters to improve the model. The most commonly tuned parameters are:\n",
        "\n",
        "- `max_depth`: maximum depth of the tree;\n",
        "- `min_samples_leaf`: minimum number of samples required to be at a leaf node.\n",
        "\n",
        "Tuning the parameters is left as an exercise to the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb-ZMOXNxTKq",
        "colab_type": "text"
      },
      "source": [
        "### Decision trees and overfitting\n",
        "\n",
        "Overfitting turns out to be a general property of decision trees: it is very easy to go too deep in the tree, and thus to fit details of the particular data rather than the overall properties of the distributions they are drawn from. This issue can be addressed by using **random forests**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW5fxbvXxTKr",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest\n",
        "\n",
        "A random forest is a powerful non-parametric algorithm that is an example of an **ensemble** method built on decision trees, meaning that it relies on aggregating the results of an ensemble of decision trees. The ensemble of trees are randomized and the output is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Evaldas_Vaiciukynas/publication/301638643/figure/fig1/AS:355471899807744@1461762513154/Architecture-of-the-random-forest-model.png\">\n",
        "\n",
        "The somewhat surprising result with such ensemble methods is that the sum can be greater than the parts: that is, a majority vote among a number of estimators can end up being better than any of the individual estimators doing the voting!\n",
        "\n",
        "### Building a Random Forest Classification Model\n",
        "\n",
        "We will use the above data used in the Decision Tree classifier in this Random Forest classifier. \n",
        "\n",
        "#### Imports\n",
        "First, we need to import `sklearn`'s `RandomForestClassfier`. All other imports needed were declared above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjzOzSH9xTKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68gwOC61xTKx",
        "colab_type": "text"
      },
      "source": [
        "#### Training\n",
        "We will now fit a Random Forest Classification model to our data by using `sklearn`'s `RandomForestClassifier` with default parameters, a random state of 42, and the number of trees set to 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1MgrQg8xTKy",
        "colab_type": "code",
        "colab": {},
        "outputId": "f1eceff8-b4ce-4f09-b731-38cb82680c5f"
      },
      "source": [
        "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "forest.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsEW3ME5xTK3",
        "colab_type": "text"
      },
      "source": [
        "#### Testing\n",
        "\n",
        "As we did with the Decision Tree model, let's predict the labels for our test set and examine the performance of our model using a confusion matix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMl1Y9NRxTK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_forest = forest.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLVTUG3fxTK8",
        "colab_type": "code",
        "colab": {},
        "outputId": "26d67f6c-faaf-4115-edb4-ffb2109e0e26"
      },
      "source": [
        "labels = ['Iris-setosa', 'Iris-versicolor','Iris-virginica']\n",
        "\n",
        "pd.DataFrame(data=confusion_matrix(y_test, pred_forest), index=labels, columns=labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Iris-setosa</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iris-virginica</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "Iris-setosa               14                0               0\n",
              "Iris-versicolor            0               16               1\n",
              "Iris-virginica             0                1              13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-M_6LDXxTLB",
        "colab_type": "text"
      },
      "source": [
        "Let's also take a look at the classification report for our predicted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh1FAFRJxTLC",
        "colab_type": "code",
        "colab": {},
        "outputId": "75510de1-82bf-44b0-b4b2-c0ad2cc1f2cd"
      },
      "source": [
        "print(classification_report(y_test, pred_forest, target_names=['Iris-setosa', 'Iris-versicolor','Iris-virginica']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        14\n",
            "Iris-versicolor       0.94      0.94      0.94        17\n",
            " Iris-virginica       0.93      0.93      0.93        14\n",
            "\n",
            "       accuracy                           0.96        45\n",
            "      macro avg       0.96      0.96      0.96        45\n",
            "   weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIo8MwVOxTLG",
        "colab_type": "text"
      },
      "source": [
        "### Tuning parameters to Improve Model\n",
        "\n",
        "For the Random Forest algorithm we can tune parameters to improve the model. The most commonly tuned parameters are:\n",
        "\n",
        "- `n_estimators`: number of trees to include in forest;\n",
        "- `max_depth`: maximum depth of the tree;\n",
        "- `min_samples_leaf`: minimum number of samples required to be at a leaf node.\n",
        "\n",
        "Tuning the parameters is left as an exercise to the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLB7y-QwxTLH",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "The Random Forest model performs similar to the Decision Tree models. This is likely due to the fact that our dataset is small and rather uncomplicated. Practise your model-building skills with other datasets and try to build an intuition about which models work best for different types of tasks/datasets.\n",
        "\n",
        "In this train we covered building Decision Tree and Random Forest Classification models using `sklearn`.\n",
        "\n",
        "## Additional Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "4uMUYi_WxTLI",
        "colab_type": "text"
      },
      "source": [
        "[sklearn Decision Tree Classification documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "\n",
        "[sklearn Random Forest Classification documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ]
    }
  ]
}